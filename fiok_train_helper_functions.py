import yaml
import cv2
import os
import glob
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"
import numpy as np

def load_yaml_config(file_path):
    """
    Beolvassa a YAML konfigurÃ¡ciÃ³s fÃ¡jlt.

    :param file_path: Az elÃ©rÃ©si Ãºt a YAML fÃ¡jlhoz.
    :return: A YAML fÃ¡jl tartalma Python dictionary-kÃ©nt.
    """
    try:
        with open(file_path, 'r') as file:
            config = yaml.safe_load(file)  # A safe_load biztonsÃ¡gosabb, mint a load
            return config
    except FileNotFoundError:
        print(f"Hiba: A fÃ¡jl nem talÃ¡lhatÃ³: {file_path}")
    except yaml.YAMLError as e:
        print(f"Hiba tÃ¶rtÃ©nt a YAML beolvasÃ¡sakor: {e}")

def adjust_brightness_contrast(image, alpha=1.2, beta=20):
    """
    Alkalmaz kontraszt Ã©s fÃ©nyerÅ‘ mÃ³dosÃ­tÃ¡st.
    alpha: A kontraszt (1.0 nem vÃ¡ltoztat semmit, >1.0 nÃ¶veli, <1.0 csÃ¶kkenti).
    beta: A fÃ©nyerÅ‘ (0 nem vÃ¡ltoztat semmit, pozitÃ­v Ã©rtÃ©k nÃ¶veli, negatÃ­v csÃ¶kkenti).
    """
    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)

def histogram_equalization(image):
    """
    HistogramaegyenlÃ­tÃ©s szÃ¼rkeÃ¡rnyalatÃº kÃ©peken.
    """
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    equalized_image = cv2.equalizeHist(gray_image)
    return cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2BGR)

def clahe(image):
    """
    CLAHE (Contrast Limited Adaptive Histogram Equalization) alkalmazÃ¡sa.
    """
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    clahe_image = clahe.apply(gray_image)
    return cv2.cvtColor(clahe_image, cv2.COLOR_GRAY2BGR)

def denoise_image(image):
    """
    ZajcsÃ¶kkentÃ©s a kÃ©pen bilaterÃ¡lis szÅ±rÃ©ssel.
    """
    return cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)


def create_mosaic(images, titles, rows, cols):
    """
    KÃ©pek Ã©s feliratok alapjÃ¡n mozaik lÃ©trehozÃ¡sa.
    images: A kÃ©pek listÃ¡ja.
    titles: A kÃ©pekhez tartozÃ³ feliratok listÃ¡ja.
    rows: A mozaik sorainak szÃ¡ma.
    cols: A mozaik oszlopainak szÃ¡ma.
    """
    # A kÃ©pek Ã¡tmÃ©retezÃ©se, hogy illeszkedjenek a mozaikba
    max_height = max([img.shape[0] for img in images])
    max_width = max([img.shape[1] for img in images])

    # Ãšj, Ã¼res mozaik kÃ©szÃ­tÃ©se
    mosaic = np.zeros((max_height * rows, max_width * cols, 3), dtype=np.uint8)

    # A kÃ©pek elhelyezÃ©se a mozaikban
    for idx, img in enumerate(images):
        row = idx // cols
        col = idx % cols
        y_offset = row * max_height
        x_offset = col * max_width
        mosaic[y_offset:y_offset + img.shape[0], x_offset:x_offset + img.shape[1]] = img

        # Felirat hozzÃ¡adÃ¡sa a kÃ©p alÃ¡
        font = cv2.FONT_HERSHEY_SIMPLEX
        text = titles[idx]
        position = (x_offset + 10, y_offset + img.shape[0] - 10)
        cv2.putText(mosaic, text, position, font, 1, (255, 255, 255), 2, cv2.LINE_AA)

    return mosaic

def train_data_flip():
    # ğŸ“‚ KÃ¶nyvtÃ¡r megadÃ¡sa, ahol a kÃ©pek Ã©s annotÃ¡ciÃ³k vannak
    input_dir_images = os.path.join("train", "images")
    input_dir_labels = os.path.join("train", "labels")

    # ğŸ” Ã–sszegyÅ±jtjÃ¼k az Ã¶sszes kÃ©p fÃ¡jlt (jpg, png, stb.)
    image_files = glob.glob(os.path.join(input_dir_images, "*.jpg")) + glob.glob(os.path.join(input_dir_images, "*.png"))

    # ğŸ”„ Minden fÃ¡jlra vÃ©grehajtjuk a tÃ¼krÃ¶zÃ©st
    for image_path in image_files:
        # ğŸ“Œ AlapfÃ¡jlnevek elÅ‘kÃ©szÃ­tÃ©se
        base_name = os.path.splitext(os.path.basename(image_path))[0]  # Pl.: "image1"
        annotation_path = os.path.join(input_dir_labels, f"{base_name}.txt")  # YOLO annotÃ¡ciÃ³ fÃ¡jl

        # ğŸ“Œ KÃ©p beolvasÃ¡sa OpenCV-vel
        image = cv2.imread(image_path)
        if image is None:
            print(f"Hiba a kÃ©p beolvasÃ¡sakor: {image_path}")
            continue

        # ğŸ“Œ KÃ©p vÃ­zszintes tÃ¼krÃ¶zÃ©se (horizontal flip)
        flipped_image = cv2.flip(image, 1)

        # ğŸ“Œ Ãšj fÃ¡jlnevek generÃ¡lÃ¡sa (_flip kiegÃ©szÃ­tÃ©ssel)
        flipped_image_path = os.path.join(input_dir_images, f"{base_name}_flip.jpg")
        flipped_annotation_path = os.path.join(input_dir_labels, f"{base_name}_flip.txt")

        # ğŸ’¾ KÃ©p mentÃ©se Ãºj fÃ¡jlkÃ©nt
        cv2.imwrite(flipped_image_path, flipped_image)

        # ğŸ”„ AnnotÃ¡ciÃ³ mÃ³dosÃ­tÃ¡sa, ha lÃ©tezik a TXT fÃ¡jl
        if os.path.exists(annotation_path):
            with open(annotation_path, "r") as f:
                lines = f.readlines()

            flipped_annotations = []
            for line in lines:
                parts = line.strip().split()
                if len(parts) != 5:
                    continue  # HibÃ¡s sorokat kihagyjuk

                class_id, x_center, y_center, width, height = map(float, parts)

                # ğŸ“Œ X koordinÃ¡ta tÃ¼krÃ¶zÃ©se
                new_x_center = 1.0 - x_center  # X flip: 1 - x_center

                # Ãšj annotÃ¡ciÃ³ formÃ¡zÃ¡sa
                flipped_annotations.append(
                    f"{int(class_id)} {new_x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")

            # ğŸ’¾ Ãšj annotÃ¡ciÃ³s fÃ¡jl mentÃ©se
            with open(flipped_annotation_path, "w") as f:
                f.writelines(flipped_annotations)

    #print(f"Mentve: {flipped_image_path}, {flipped_annotation_path}")
    print("#INFO: TÃ¼krÃ¶zÃ¶tt kÃ©pek Ã©s mÃ³dosÃ­tott txt fÃ¡jlok mentÃ©se kÃ©sz")